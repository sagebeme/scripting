# Level 9: Networking & APIs

## üìã Learning Objectives

By the end of this module, you will be able to:
- Make HTTP requests
- Work with REST APIs
- Handle JSON responses
- Scrape web content
- Authenticate with APIs
- Handle API errors
- Work with rate limits
- Build API clients

## üìö Topics Covered

### 1. HTTP Requests
- requests library
- GET, POST, PUT, DELETE
- Request headers
- Query parameters
- Request body
- Response handling

### 2. REST API Integration
- API endpoints
- HTTP methods
- Status codes
- Response formats
- API documentation

### 3. JSON Handling
- JSON encoding/decoding
- Parsing JSON responses
- Creating JSON payloads
- Nested JSON structures

### 4. Web Scraping Basics
- BeautifulSoup
- HTML parsing
- Element selection
- Data extraction
- Ethical scraping

### 5. Authentication
- API keys
- OAuth 2.0
- Bearer tokens
- Basic authentication
- Session management

### 6. Error Handling
- HTTP errors
- Network errors
- Timeout handling
- Retry logic
- Error logging

### 7. Rate Limiting
- Understanding rate limits
- Implementing delays
- Exponential backoff
- Respecting API limits

### 8. Working with APIs
- GitHub API
- Twitter API
- Weather APIs
- News APIs
- Custom APIs

### 9. Advanced Topics
- Async requests
- WebSockets
- Streaming responses
- File uploads/downloads

### 10. Best Practices
- API key security
- Error handling
- Rate limiting
- Caching
- Documentation

## üéØ Exercises

**Location**: See the [`exercises/`](./exercises/) directory for hands-on practice files.

### Exercise 1: HTTP Requests
- Make GET requests
- Handle responses
- Work with headers

### Exercise 2: REST API
- Interact with REST API
- Handle JSON responses
- Parse data

### Exercise 3: Web Scraping
- Parse HTML
- Extract data
- Handle errors

### Exercise 4: Authentication
- Use API keys
- Handle OAuth
- Manage sessions

### Exercise 5: Error Handling
- Handle HTTP errors
- Implement retries
- Log errors

## üöÄ Projects

**Location**: See the [`projects/`](./projects/) directory for project templates.

### Project 1: API Client Tool
Build a client for a public API.

### Project 2: Web Scraper
Scrape data from websites.

### Project 3: Data Aggregator
Aggregate data from multiple APIs.

### Project 4: Social Media Automation
Automate social media tasks.

## üìù Example Scripts

**Location**: See the [`examples/`](./examples/) directory for working examples.

### Example 1: HTTP Requests
Demonstrate requests library.

### Example 2: API Integration
Show API interaction.

### Example 3: Web Scraping
Demonstrate BeautifulSoup.

## üîç Key Concepts

### HTTP Requests
```python
import requests

response = requests.get('https://api.example.com/data')
data = response.json()
```

### API with Authentication
```python
headers = {'Authorization': 'Bearer token'}
response = requests.get(url, headers=headers)
```

### Web Scraping
```python
from bs4 import BeautifulSoup

soup = BeautifulSoup(html, 'html.parser')
title = soup.find('h1').text
```

## ‚úÖ Checklist

Before moving to the next module, ensure you can:
- [ ] Make HTTP requests
- [ ] Work with REST APIs
- [ ] Handle JSON data
- [ ] Scrape web content
- [ ] Authenticate with APIs
- [ ] Handle errors properly
- [ ] Respect rate limits
- [ ] Complete all exercises
- [ ] Build at least one project

## üìö Additional Resources

### Documentation
- [requests library](https://requests.readthedocs.io/)
- [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)

### Learning
- [Real Python - HTTP Requests](https://realpython.com/python-requests/)
- [Web Scraping Guide](https://realpython.com/beautiful-soup-web-scraper-python/)

### APIs
- [Public APIs](https://github.com/public-apis/public-apis)
- [JSONPlaceholder](https://jsonplaceholder.typicode.com/) - Test API

## üéì Next Steps

Once you've completed this module:
1. Practice with different APIs
2. Master web scraping
3. Build API clients
4. Move to **10-databases** module

---

**Remember**: Always respect API rate limits and terms of service. Be ethical with web scraping!
